{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qdhCtTrBfGH","executionInfo":{"status":"ok","timestamp":1724703233038,"user_tz":240,"elapsed":24120,"user":{"displayName":"Lars Lien Ankile","userId":"12768464313641053119"}},"outputId":"8e47a271-e32a-4df8-aaa0-3b2555fce363"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from pathlib import Path"],"metadata":{"id":"y9n8qtqvBq0l","executionInfo":{"status":"ok","timestamp":1724703237232,"user_tz":240,"elapsed":204,"user":{"displayName":"Lars Lien Ankile","userId":"12768464313641053119"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["base_path = Path(\"/content/drive/MyDrive/10 â€“ Harvard/4. Semester/sim-2-real-representation-learning/data\")"],"metadata":{"id":"COHI-oudBtM1","executionInfo":{"status":"ok","timestamp":1724703238374,"user_tz":240,"elapsed":207,"user":{"displayName":"Lars Lien Ankile","userId":"12768464313641053119"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLn79l2EW2lr","executionInfo":{"status":"ok","timestamp":1722623428219,"user_tz":240,"elapsed":187,"user":{"displayName":"Lars Lien Ankile","userId":"12768464313641053119"}},"outputId":"0eb17188-681d-47f3-bf9a-9dc8843fbcde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Aug  2 18:30:28 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"A19D_rL3eixs","executionInfo":{"status":"ok","timestamp":1724703464458,"user_tz":240,"elapsed":14039,"user":{"displayName":"Lars Lien Ankile","userId":"12768464313641053119"}}},"outputs":[],"source":["%%capture\n","# Install the library with the pretrained weights\n","!pip install git+https://github.com/facebookresearch/r3m.git\n","!pip install zarr"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"0e6TFtI9ewYg","executionInfo":{"status":"ok","timestamp":1724703477915,"user_tz":240,"elapsed":7501,"user":{"displayName":"Lars Lien Ankile","userId":"12768464313641053119"}}},"outputs":[],"source":["import torch\n","import zarr\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from r3m import load_r3m\n","\n","from tqdm import trange\n","\n","# Import t-SNE and PCA\n","from sklearn.manifold import TSNE\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"executionInfo":{"elapsed":566,"status":"error","timestamp":1724703478479,"user":{"displayName":"Lars Lien Ankile","userId":"12768464313641053119"},"user_tz":240},"id":"oQ-oV_MBazkg","outputId":"3c762311-8a17-490d-d759-b5d6322ec886"},"outputs":[{"output_type":"error","ename":"PathNotFoundError","evalue":"nothing found at path ''","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPathNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-d950dd1620f1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msim1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"one_leg_low_sim.zarr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"one_leg_med_sim.zarr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"one_leg_low_real.zarr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zarr/convenience.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(store, mode, zarr_version, path, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPathNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPathNotFoundError\u001b[0m: nothing found at path ''"]}],"source":["# Load the data\n","sim1 = zarr.open(base_path / \"one_leg_low_sim.zarr\", mode=\"r\")\n","sim2 = zarr.open(base_path / \"one_leg_med_sim.zarr\", mode=\"r\")\n","real = zarr.open(base_path / \"one_leg_low_real.zarr\", mode=\"r\")\n","\n","sim1_imgs = sim1[\"color_image2\"]\n","sim2_imgs = sim2[\"color_image2\"]\n","real_imgs = real[\"color_image2\"]\n","\n","print(f\"Loaded {len(sim1['episode_ends'])} trajectories containing {sim1_imgs.shape[0]} frames\")\n","print(f\"Loaded {len(sim2['episode_ends'])} trajectories containing {sim2_imgs.shape[0]} frames\")\n","print(f\"Loaded {len(real['episode_ends'])} trajectories containing {real_imgs.shape[0]} frames\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I_mPe0iHyl9Z"},"outputs":[],"source":["# Sample 8 images from each dataset\n","sim1_indices = np.random.choice(sim1_imgs.shape[0], size=8, replace=False)\n","sim2_indices = np.random.choice(sim2_imgs.shape[0], size=8, replace=False)\n","real_indices = np.random.choice(real_imgs.shape[0], size=8, replace=False)\n","\n","# Create a figure and axes\n","fig, axes = plt.subplots(3, 8, figsize=(20, 5))\n","\n","# Display the sampled images\n","for i, idx in enumerate(sim1_indices):\n","    axes[0, i].imshow(sim1_imgs[idx])\n","    axes[0, i].axis('off')\n","\n","for i, idx in enumerate(sim2_indices):\n","    axes[1, i].imshow(sim2_imgs[idx])\n","    axes[1, i].axis('off')\n","\n","for i, idx in enumerate(real_indices):\n","    axes[2, i].imshow(real_imgs[idx])\n","    axes[2, i].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4GAgbvtewmT"},"outputs":[],"source":["# Load the encoder with pretrained weights\n","r3m = load_r3m(\"resnet18\").cuda().eval()\n"]},{"cell_type":"markdown","metadata":{"id":"0-Hf0ifJz1Jy"},"source":["The forward function of the r3m model looks like this:\n","\n","```python\n","## Forward Call (im --> representation)\n","def forward(self, obs, num_ims = 1, obs_shape = [3, 224, 224]):\n","    if obs_shape != [3, 224, 224]:\n","        preprocess = nn.Sequential(\n","                    transforms.Resize(256),\n","                    transforms.CenterCrop(224),\n","                    self.normlayer,\n","            )\n","    else:\n","        preprocess = nn.Sequential(\n","                    self.normlayer,\n","            )\n","\n","    ## Input must be [0, 255], [3,244,244]\n","    obs = obs.float() /  255.0\n","    obs_p = preprocess(obs)\n","    h = self.convnet(obs_p)\n","    return h\n","```\n","\n","which means that we need to pass it images that are not normalized, but have the channel dimension first (last is default in our data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cwh-O9B2y_MO"},"outputs":[],"source":["# Assuming the encoder expects images of size (3, 224, 224) [0, 255]\n","random_input = torch.randint(0, 255, size=(1, 3, 224, 224))\n","\n","# Pass the random data through the encoder\n","with torch.no_grad():\n","  output = r3m(random_input)\n","\n","# Print the shape and data type of the output\n","print(\"Output shape:\", output.shape)\n","print(\"Output data type:\", output.dtype)\n","print(f\"I.e., the embedding dimension of this resnet is {output.shape[1]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vfTDpUDkz4zd"},"outputs":[],"source":["# Sample 1000 images from each dataset\n","num_samples = 1000\n","sim1_indices = np.random.choice(sim1_imgs.shape[0], size=num_samples, replace=False)\n","sim2_indices = np.random.choice(sim2_imgs.shape[0], size=num_samples, replace=False)\n","real_indices = np.random.choice(real_imgs.shape[0], size=num_samples, replace=False)\n","\n","# Create tensors to store the embeddings\n","sim1_embeddings = torch.zeros(num_samples, output.shape[1])\n","sim2_embeddings = torch.zeros(num_samples, output.shape[1])\n","real_embeddings = torch.zeros(num_samples, output.shape[1])\n","\n","# Compute embeddings for the sampled images in batches, storing in pre-allocated tensors\n","batch_size = 200  # Adjust as needed\n","\n","with torch.no_grad():\n","  for i in trange(0, num_samples, batch_size):\n","    # Process sim1 images in batches\n","    batch_indices = sim1_indices[i: i + batch_size]\n","    sim_batch = torch.tensor(sim1_imgs[batch_indices]).permute(0, 3, 1, 2).float().cuda()\n","    sim1_embeddings[i: i + batch_size] = r3m(sim_batch).cpu()\n","\n","    # Process sim2 images in batches\n","    batch_indices = sim2_indices[i: i + batch_size]\n","    sim_batch = torch.tensor(sim2_imgs[batch_indices]).permute(0, 3, 1, 2).float().cuda()\n","    sim2_embeddings[i: i + batch_size] = r3m(sim_batch).cpu()\n","\n","    # Process real images in batches\n","    batch_indices = real_indices[i: i + batch_size]\n","    real_batch = torch.tensor(real_imgs[batch_indices]).permute(0, 3, 1, 2).float().cuda()\n","    real_embeddings[i: i + batch_size] = r3m(real_batch).cpu()\n","\n","# Embeddings are now stored in sim_embeddings and real_embeddings tensors\n","# Concatenate the embeddings and create labels\n","all_embeddings = torch.cat([sim1_embeddings, sim2_embeddings, real_embeddings]).cpu().numpy()\n","labels = np.concatenate([np.zeros(num_samples), np.ones(num_samples), np.ones(num_samples) * 2])\n","\n","# Fit t-SNE on the embeddings\n","tsne = TSNE(n_components=2)\n","embeddings_2d = tsne.fit_transform(all_embeddings)\n","\n","# Plot the 2D embeddings\n","plt.figure(figsize=(8, 6))\n","plt.scatter(embeddings_2d[:num_samples, 0], embeddings_2d[:num_samples, 1], label='Sim (low)', alpha=0.5)\n","plt.scatter(embeddings_2d[num_samples:2*num_samples, 0], embeddings_2d[num_samples:2*num_samples, 1], label='Sim (med)', alpha=0.5)\n","plt.scatter(embeddings_2d[2*num_samples:, 0], embeddings_2d[2*num_samples:, 1], label='Real', alpha=0.5)\n","plt.xlabel('t-SNE Dimension 1')\n","plt.ylabel('t-SNE Dimension 2')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0UqVDOE2tX-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"16M6OeJEXnAYxM07D5Y5VD6nxZ5xgINCO","timestamp":1721745375879}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}